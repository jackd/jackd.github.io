[ { "title": "Negative Gearing and the CGT Discount: A Modern Portfolio Theory Analysis", "url": "/posts/mpt/", "categories": "", "tags": "finance", "date": "2025-07-14 11:00:01 +1000", "snippet": "IntroductionThe capital gains tax (CGT) discount was introduced in Australia in 1999 to simplify and incentivize investment in the share market. More recently, in the midst of a housing crisis, treasury has advised that the discount has a very small affect on home prices - of the order of 1-2% - ..." }, { "title": "Retention LLMs: Analysing Algorithms and Alternative Implementations", "url": "/posts/retention/", "categories": "keras, LLM, jax", "tags": "performance, benchmarks", "date": "2023-10-01 11:00:01 +1000", "snippet": "Retention networks have been making waves in the large language model scene, with big claims about the potential to replace transformers with training parallelism, cheaper inference and good performance. I noticed some similarities with other work on RWKV and fast attention and wanted to see if a..." }, { "title": "Faster LLMs: Improving RWKV with Parallel Cumulative Sums", "url": "/posts/improving-rwkv/", "categories": "Tensorflow, pytorch, jax, keras, LLM", "tags": "performance, benchmarks", "date": "2023-10-01 11:00:01 +1000", "snippet": "Large language models are all the craze right now. I was keen to learn about keras-nlp - keras’ natural language processing framework - and recent methods, so I decided to implement RWKV, a popular model originally implemented in pytorch that’s fostered a surprisingly large ecosystem of tools and..." }, { "title": "Simple Fast Attention: Causal Implementation Experiments", "url": "/posts/simple-fast-attention/", "categories": "Tensorflow, Machine Learning, Linear Algebra", "tags": "performance, benchmarks", "date": "2022-11-30 11:00:01 +1000", "snippet": "Having looked at google-research’s fast attention tensorflow implementation and corresponding blog post, I was left scratching my head about the causal attention implementation. This post discusses a simpler implementation.TL;DRWe provide implementations for computing low-rank causal attention eq..." }, { "title": "How the Omicron Wave will be Different", "url": "/posts/omicrons-different/", "categories": "Modelling", "tags": "covid, epidemiology", "date": "2021-12-22 11:00:01 +1000", "snippet": "TL;DR Omicron cases are projected to double every 2-3 days until a significant proportion of the population has become infected. This will result in a wave like nothing we have seen in Australia or oversease before. The peak in daily infections will be here sooner than you think, hit harder tha..." }, { "title": "Digging into Doherty: Implications of Initialization", "url": "/posts/doherty-init/", "categories": "Modelling", "tags": "covid, epidemiology", "date": "2021-08-25 11:00:01 +1000", "snippet": "The Doherty institute recently released a report that led to an agreement between state and federal leaders about a roadmap to transition out of lockdown-management of covid19. Models looked at a variety of scenarios by simulating outbreaks with 30 infected individuals. The current outbreak in Sy..." }, { "title": "Deep Equilibrium Models in Jax", "url": "/posts/deq/", "categories": "Linear Algebra", "tags": "jax, autograd", "date": "2021-07-20 11:00:01 +1000", "snippet": "Implicit layers and Deep Equilibrium models (DEQ) have recently been proposed as memory-efficient alternatives to super-deep networks. In this post we explore: the mathematical background behind implicit layers and gradients used by auto-differentiation systems; jax implementations, including J..." }, { "title": "Micro-benchmarking in TF2", "url": "/posts/micro-benchmarks-tf2/", "categories": "Tensorflow, Machine Learning", "tags": "performance, benchmarks", "date": "2021-01-23 11:00:01 +1000", "snippet": "TL;DR: TF2 Benchmarks don’t have to be hard to write. See example at the bottom and/or tfbm. “Premature optimization is the root of all evil.”– Donald KnuthThis quote is ubiquitous in software circles, and is arguably even more relevant today than it was back in 1974. However, it is all too ofte..." }, { "title": "Generalized Eigenvalue Problem Derivatives", "url": "/posts/generalized-eig-jvp/", "categories": "Linear Algebra", "tags": "jax, autograd", "date": "2021-01-21 11:00:01 +1000", "snippet": "The eigenvector problem is ubiquitous in many areas of mathematics, physics and computer science. I recently found myself needing the solution to the generalized eigenvalue problem and discovered an implementation doesn’t exist in jax. While wrapping low-level cuda code is mechanical enough, this..." }, { "title": "Deterministic Tensorflow Part 2: Data Augmentation", "url": "/posts/deterministic-tf-part-2/", "categories": "Tensorflow, Training", "tags": "deterministic, pre-emptible", "date": "2020-12-06 11:00:01 +1000", "snippet": "Data augmentation is commonly used to artificially inflate the size of training datasets and teach networks invariances to various transformations. For example, image classification networks often train better when their datasets are augmented with random rotations, lighting adjustments and rando..." }, { "title": "Deterministic Tensorflow Part 1: Model Training", "url": "/posts/deterministic-tf-part-1/", "categories": "Tensorflow, Data", "tags": "pipeline, performance, parallel, deterministic, pre-emptible", "date": "2020-12-06 11:00:00 +1000", "snippet": "Reproducibility is critical to any scientific endeavour, and machine learning is no exception. Releasing code that generates results from papers is an important step in addressing this, but difficulties arise in random aspect of neural network training including data shuffling, augmentation and n..." } ]
